{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "\n",
    "#@jit\n",
    "def mcc(tp, tn, fp, fn):\n",
    "    sup = tp * tn - fp * fn\n",
    "    inf = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    if inf==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sup / np.sqrt(inf)\n",
    "\n",
    "#@jit\n",
    "def eval_mcc(y_true, y_prob, show=False):\n",
    "    idx = np.argsort(y_prob)\n",
    "    y_true_sort = y_true[idx]\n",
    "    n = y_true.shape[0]\n",
    "    nump = 1.0 * np.sum(y_true) # number of positive\n",
    "    numn = n - nump # number of negative\n",
    "    tp = nump\n",
    "    tn = 0.0\n",
    "    fp = numn\n",
    "    fn = 0.0\n",
    "    best_mcc = 0.0\n",
    "    best_id = -1\n",
    "    prev_proba = -1\n",
    "    best_proba = -1\n",
    "    mccs = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        # all items with idx < i are predicted negative while others are predicted positive\n",
    "        # only evaluate mcc when probability changes\n",
    "        proba = y_prob[idx[i]]\n",
    "        if proba != prev_proba:\n",
    "            prev_proba = proba\n",
    "            new_mcc = mcc(tp, tn, fp, fn)\n",
    "            if new_mcc >= best_mcc:\n",
    "                best_mcc = new_mcc\n",
    "                best_id = i\n",
    "                best_proba = proba\n",
    "        mccs[i] = new_mcc\n",
    "        if y_true_sort[i] == 1:\n",
    "            tp -= 1.0\n",
    "            fn += 1.0\n",
    "        else:\n",
    "            fp -= 1.0\n",
    "            tn += 1.0\n",
    "    if show:\n",
    "        y_pred = (y_prob >= best_proba).astype(int)\n",
    "        score = matthews_corrcoef(y_true, y_pred)\n",
    "        print(score, best_mcc)\n",
    "        plt.plot(mccs)\n",
    "        return best_proba, best_mcc, y_pred\n",
    "    else:\n",
    "        return best_mcc\n",
    "\n",
    "def mcc_eval(y_prob, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    best_mcc = eval_mcc(y_true, y_prob)\n",
    "    return 'MCC', best_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.18.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_hdf('../../search/feats/tr_time_diff_adjacent12.hdf5','table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('../../input_orig/train_numeric.csv', usecols=['Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size=0.2, random_state=42, stratify=y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "del X_train\n",
    "del y_train\n",
    "gc.collect()\n",
    "\n",
    "dval = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "del X_test\n",
    "del y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prior = (np.sum(y) / (1.*len(y))).values[0]\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bytree': 1,\n",
    "    'colsample_bylevel': 1,\n",
    "    'subsample': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'base_score': prior,\n",
    "    #'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0,\n",
    "    'seed': 12,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "evals  = [(dtrain,'train'), (dval,'eval')]\n",
    "bst = xgb.train(xgb_params, dtrain, num_boost_round=50000, early_stopping_rounds=20, \n",
    "                 evals=evals, verbose_eval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_pred = bst.predict(dval, ntree_limit=bst.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcc_eval(val_pred, dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#eval_mcc(dval.get_label(), val_pred, show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prior = (np.sum(y) / (1.*len(y))).values[0]\n",
    "\n",
    "xgb_params1 = {\n",
    "    'colsample_bytree': 1,\n",
    "    'colsample_bylevel': 1,\n",
    "    'subsample': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'base_score': prior,\n",
    "    #'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0,\n",
    "    'seed': 12,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "evals  = [(dtrain,'train'), (dval,'eval')]\n",
    "bst1 = xgb.train(xgb_params1, dtrain, num_boost_round=50000, early_stopping_rounds=20, \n",
    "                 evals=evals, verbose_eval=1, feval=mcc_eval, maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-MCC:0.164093\teval-MCC:0.147757\n",
      "Multiple eval metrics have been passed: 'eval-MCC' will be used for early stopping.\n",
      "\n",
      "Will train until eval-MCC hasn't improved in 20 rounds.\n"
     ]
    }
   ],
   "source": [
    "prior = (np.sum(y) / (1.*len(y))).values[0]\n",
    "\n",
    "xgb_params2 = {\n",
    "    'colsample_bytree': 1,\n",
    "    'colsample_bylevel': 1,\n",
    "    'subsample': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'base_score': prior,\n",
    "    'num_parallel_tree': 10,\n",
    "    #'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0,\n",
    "    'seed': 12,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "evals  = [(dtrain,'train'), (dval,'eval')]\n",
    "bst2 = xgb.train(xgb_params2, dtrain, num_boost_round=1, early_stopping_rounds=20, \n",
    "                 evals=evals, verbose_eval=1, feval=mcc_eval, maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-MCC:0.187311\teval-MCC:0.152543\n",
      "Multiple eval metrics have been passed: 'eval-MCC' will be used for early stopping.\n",
      "\n",
      "Will train until eval-MCC hasn't improved in 20 rounds.\n"
     ]
    }
   ],
   "source": [
    "prior = (np.sum(y) / (1.*len(y))).values[0]\n",
    "\n",
    "xgb_params3 = {\n",
    "    'colsample_bytree': 1,\n",
    "    'colsample_bylevel': 1,\n",
    "    'subsample': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'base_score': prior,\n",
    "    'num_parallel_tree': 10,\n",
    "    #'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0,\n",
    "    'seed': 12,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "evals  = [(dtrain,'train'), (dval,'eval')]\n",
    "bst3 = xgb.train(xgb_params3, dtrain, num_boost_round=1, early_stopping_rounds=20, \n",
    "                 evals=evals, verbose_eval=1, feval=mcc_eval, maximize=True, xgb_model=bst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_pred2 = bst2.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61968873949198322"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(dval.get_label(), val_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MCC', 0.14775725336057771)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_eval(val_pred2, dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bst2.get_score(fmap='', importance_type='gain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.628627757203\n",
      "('MCC', 0.15254323873498979)\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "val_pred3 = bst3.predict(dval)\n",
    "print(roc_auc_score(dval.get_label(), val_pred3))\n",
    "print(mcc_eval(val_pred3, dval))\n",
    "print(len(bst3.get_score(fmap='', importance_type='gain')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-MCC:0.204316\teval-MCC:0.157513\n",
      "Multiple eval metrics have been passed: 'eval-MCC' will be used for early stopping.\n",
      "\n",
      "Will train until eval-MCC hasn't improved in 20 rounds.\n",
      "0.635648390595\n",
      "('MCC', 0.15751290159005946)\n",
      "233\n"
     ]
    }
   ],
   "source": [
    "prior = (np.sum(y) / (1.*len(y))).values[0]\n",
    "\n",
    "xgb_params3 = {\n",
    "    'colsample_bytree': 1,\n",
    "    'colsample_bylevel': 1,\n",
    "    'subsample': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'base_score': prior,\n",
    "    'num_parallel_tree': 20,\n",
    "    #'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0,\n",
    "    'seed': 12,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "evals  = [(dtrain,'train'), (dval,'eval')]\n",
    "bst4 = xgb.train(xgb_params3, dtrain, num_boost_round=1, early_stopping_rounds=20, \n",
    "                 evals=evals, verbose_eval=1, feval=mcc_eval, maximize=True, xgb_model=bst3)\n",
    "val_pred3 = bst4.predict(dval)\n",
    "print(roc_auc_score(dval.get_label(), val_pred3))\n",
    "print(mcc_eval(val_pred3, dval))\n",
    "print(len(bst4.get_score(fmap='', importance_type='gain')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-MCC:0.209037\teval-MCC:0.157331\n",
      "Multiple eval metrics have been passed: 'eval-MCC' will be used for early stopping.\n",
      "\n",
      "Will train until eval-MCC hasn't improved in 20 rounds.\n",
      "0.640980759579\n",
      "('MCC', 0.15733091946411609)\n",
      "277\n"
     ]
    }
   ],
   "source": [
    "prior = (np.sum(y) / (1.*len(y))).values[0]\n",
    "\n",
    "xgb_params3 = {\n",
    "    'colsample_bytree': 1,\n",
    "    'colsample_bylevel': 1,\n",
    "    'subsample': 1,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'base_score': prior,\n",
    "    'num_parallel_tree': 10,\n",
    "    #'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0,\n",
    "    'seed': 12,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "evals  = [(dtrain,'train'), (dval,'eval')]\n",
    "bst5 = xgb.train(xgb_params3, dtrain, num_boost_round=1, early_stopping_rounds=20, \n",
    "                 evals=evals, verbose_eval=1, feval=mcc_eval, maximize=True, xgb_model=bst4)\n",
    "val_pred3 = bst5.predict(dval)\n",
    "print(roc_auc_score(dval.get_label(), val_pred3))\n",
    "print(mcc_eval(val_pred3, dval))\n",
    "print(len(bst5.get_score(fmap='', importance_type='gain')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-MCC:0.168643\teval-MCC:0.154525\n",
      "Multiple eval metrics have been passed: 'eval-MCC' will be used for early stopping.\n",
      "\n",
      "Will train until eval-MCC hasn't improved in 20 rounds.\n",
      "0.655206296743\n",
      "('MCC', 0.15452478072626402)\n",
      "536\n"
     ]
    }
   ],
   "source": [
    "prior = (np.sum(y) / (1.*len(y))).values[0]\n",
    "\n",
    "xgb_params3 = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'base_score': prior,\n",
    "    'num_parallel_tree': 50,\n",
    "    #'tree_method': 'exact',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 0,\n",
    "    'seed': 12,\n",
    "    'nthread': 4\n",
    "}\n",
    "\n",
    "evals  = [(dtrain,'train'), (dval,'eval')]\n",
    "bst6 = xgb.train(xgb_params3, dtrain, num_boost_round=1, early_stopping_rounds=20, \n",
    "                 evals=evals, verbose_eval=1, feval=mcc_eval, maximize=True)\n",
    "val_pred3 = bst6.predict(dval)\n",
    "print(roc_auc_score(dval.get_label(), val_pred3))\n",
    "print(mcc_eval(val_pred3, dval))\n",
    "print(len(bst6.get_score(fmap='', importance_type='gain')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb_1173_date_feats.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "from operator import itemgetter\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb_1173_date_feats.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_importance(bst1, bst1.feature_names)\n",
    "create_feature_map(bst1.feature_names)\n",
    "\n",
    "bst1.save_model('xgb_1173_date_0168mcc_0671auc.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_importance(bst1, bst1.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
