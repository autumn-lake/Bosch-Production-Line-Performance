{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_unq = pd.read_csv('input_hdf/num_unq.csv')\n",
    "cat_unq = pd.read_csv('input_hdf/cat_unq.csv')\n",
    "date_unq = pd.read_csv('input_hdf/date_unq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_train = pd.read_csv('input_orig/train_date.csv',usecols=date_unq.column.values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_train.fillna(-999999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now, let's find features with no variance \n",
    "toKeep = []\n",
    "toDelete = []\n",
    "## loop through the DataFrame's columns\n",
    "for col in date_train:\n",
    "    ## if the value_counts method returns more than one uniqe entity,\n",
    "    ## append the column name to 'toKeep'\n",
    "    if len(date_train[col].value_counts()) > 1:\n",
    "        toKeep.append(col)\n",
    "    ## if not, append to 'toDelete'.\n",
    "    else:\n",
    "        toDelete.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_train.drop(toDelete, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1183747, 162)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_matrix = date_train.corr()\n",
    "corr_matrix.to_csv('corr_matrix_date_unique.csv')\n",
    "# substitude the entire matrix for a triangular matrix for faster\n",
    "# computation\n",
    "corr_matrix.ix[:,:] =  numpy.tril(corr_matrix.values, k = -1)\n",
    "## create catcher objects to find lists of what is perfectly correlated\n",
    "already_in = set()\n",
    "result = []\n",
    "for col in corr_matrix:\n",
    "    perfect_corr = corr_matrix[col][abs(corr_matrix[col]) == 1.00].index.tolist()\n",
    "    if perfect_corr and col not in already_in:\n",
    "        already_in.update(set(perfect_corr))\n",
    "        perfect_corr.append(col)\n",
    "        result.append(perfect_corr)\n",
    "\n",
    "toRemove = []\n",
    "for item in result:\n",
    "    toRemove.append(item[1:(len(item)+1)])\n",
    "# flattenign the list of lists\n",
    "toRemove = sum(toRemove, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_train.drop(toRemove, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1183747, 162)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_train.to_hdf('train_date_162cols.hdf5','table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_test = pd.read_csv('input_orig/test_date.csv', usecols=date_train.columns.values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_train.fillna(-999999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1183748, 162)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_test.to_hdf('test_date_162cols.hdf5','table')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
